{
    "nbformat_minor": 0, 
    "metadata": {
        "language_info": {
            "pygments_lexer": "ipython2", 
            "name": "python", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11"
        }, 
        "kernelspec": {
            "language": "python", 
            "name": "python2", 
            "display_name": "Python 2 with Spark 1.6"
        }
    }, 
    "nbformat": 4, 
    "cells": [
        {
            "source": "<h1>Structured Data</h1>\n\n<h2>Spark makes it easy to work with structured data.</h2>\n<h2>Structured data is any data that has a schema, i.e., a known set of fields for each record.</h2>\n\n<h2> We can work with structure data in two ways:</h2>\n    <ul>\n    <li><h3>via Structure Query Language (SQL).</h3></li>\n    <li><h3>via DataFrames.</h3></li>\n    </ul>\n\n<h2><u>Definition</u>: A <b>DataFrame</b> is a distributed collection of data organized into named columns.</h2>", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "![StarSchema](https://github.com/ahmetbulut/CS340withDSX/blob/master/static/Week6/StarSchema.png?raw=true)\n![StarSchemaExample](https://github.com/ahmetbulut/CS340withDSX/blob/master/static/Week6/StarSchemaExample.png?raw=true)", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "# Create a DataFrame from json-ed text data (json: Java Script Object Notation).", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 2, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# The code was removed by DSX for sharing.", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 3, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "from pyspark.sql import SQLContext\nsqlContext = SQLContext(sc)\n\n#Prior to this, make sure to setup the access of Spark to your Object Storage.\ndf = sqlContext.read.json(\"swift://CS340.\" + name + \"/Intentory.json\")", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 5, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "# Prints the contents of the DataFrame to stdout\ndf.show()", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+--------+-----------+--------+---------------+--------+--------+----------------+--------------------+------------+---------+-----------+------------+--------------------+------------+-----------------+------+\n|   Brand|BuyCurrency|BuyPrice|       Category|      Id|LeadTime|MinOrderQuantity|                Name|SellCurrency|SellPrice|StockOnHand|StockOnOrder|         SubCategory|    Supplier|TargetBatchVolume|Volume|\n+--------+-----------+--------+---------------+--------+--------+----------------+--------------------+------------+---------+-----------+------------+--------------------+------------+-----------------+------+\n| StarTAC|        GBP|   27.67|     Technology|16342939|      15|               1|      StarTAC Series|         USD|    65.99|         15|          50|Telephones and Co...|Office First|              0.0|   0.8|\n|   Xerox|        CNY|    29.8|Office Supplies|16346727|       5|               1|          Xerox 1984|         USD|     6.48|         34|           1|               Paper|      Drecom|             67.5|  0.47|\n|   Xerox|        CNY|  219.54|Office Supplies|16346853|      10|               1|          Xerox 1885|         USD|    48.04|         16|          40|               Paper|      Drecom|             67.5|  0.55|\n|   Elite|        CNY|   34.12|Office Supplies|16350870|      12|               1|Elite 5 inch Scis...|         USD|     8.45|          0|           3|Scissors, Rulers ...|         FHL|              0.0|  0.85|\n|  Wilson|        CNY|    31.3|Office Supplies|16359070|      33|              10|Wilson Jones Dubl...|         USD|     6.75|         30|           0|Binders and Binde...| SuperSupply|              0.0|  0.12|\n|MicroTAC|        CNY|  261.48|     Technology|16376266|       5|               1|        MicroTAC 650|         USD|    65.99|          5|           1|Telephones and Co...|      Drecom|             67.5|  0.55|\n|   V3682|        CNY|  496.04|     Technology|16379125|       5|               1|               V3682|         USD|   125.99|         10|           0|Telephones and Co...|         FHL|              0.0|  0.41|\n|   Xerox|        CNY|  218.85|Office Supplies|16395266|      14|               1|          Xerox 1938|         USD|     47.9|         25|           0|               Paper|      Drecom|             67.5|  0.84|\n| Staples|        CNY|   25.79|Office Supplies|16397221|      17|              25|Staples Standard ...|         USD|     5.68|          0|          75|           Envelopes|     Logipro|             33.1|  0.12|\n| StarTAC|        GBP|   48.64|     Technology|16402632|      18|               1|        StarTAC 7797|         USD|   115.99|          0|           2|Telephones and Co...|Office First|              0.0|  0.97|\n|   Avery|        CNY|  188.61|Office Supplies|16405635|      20|              30|Avery Trapezoid R...|         USD|    40.98|          0|          30|Binders and Binde...|         FHL|              0.0|  0.13|\n|Anderson|        CNY|   54.15|      Furniture|16406897|       5|               1|Anderson Hickey C...|         USD|    15.23|         14|           0|              Tables|         FHL|              0.0|  0.84|\n|   SAFCO|        CNY| 2187.56|      Furniture|16411763|       5|               1|SAFCO PlanMaster ...|         USD|   349.45|         23|           4|              Tables| SuperSupply|              0.0|  0.55|\n|   Canon|        GBP|   89.04|     Technology|16413246|      24|               1|Canon PC-428 Pers...|         USD|   199.99|         11|           0|     Copiers and Fax|Office First|              0.0|   0.9|\n|It's Hot|        CNY|   33.12|Office Supplies|16421400|      33|              20|It's Hot Message ...|         USD|      7.4|          0|          60|               Paper|      Drecom|             67.5|  0.12|\n|Electrix|        PLN|   36.68|      Furniture|16422303|      20|              30|Electrix 20W Halo...|         USD|     13.4|         22|           0|  Office Furnishings|         RRD|              0.0|  0.11|\n|   Safco|        CNY|  444.33|      Furniture|16425918|      18|              25|Safco Value Mate ...|         USD|    70.98|          0|          25|           Bookcases| SuperSupply|              0.0|  0.07|\n| Catalog|        CNY|  300.86|Office Supplies|16429400|      27|              50|Catalog Binders w...|         USD|    67.28|          0|         150|Binders and Binde...|      Drecom|             67.5|  0.11|\n|  Belkin|        CNY|   42.88|Office Supplies|16431437|      22|               1|Belkin 6 Outlet M...|         USD|    10.89|         35|           0|          Appliances|         FHL|              0.0|  0.99|\n|    Iris|        CNY|   71.49|Office Supplies|16437390|      17|              45|Iris 3-Drawer Sta...|         USD|    20.89|          0|         135|Storage & Organiz...|     Logipro|             33.1|  0.11|\n+--------+-----------+--------+---------------+--------+--------+----------------+--------------------+------------+---------+-----------+------------+--------------------+------------+-----------------+------+\nonly showing top 20 rows\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 6, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "df.printSchema()", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "root\n |-- Brand: string (nullable = true)\n |-- BuyCurrency: string (nullable = true)\n |-- BuyPrice: double (nullable = true)\n |-- Category: string (nullable = true)\n |-- Id: long (nullable = true)\n |-- LeadTime: long (nullable = true)\n |-- MinOrderQuantity: long (nullable = true)\n |-- Name: string (nullable = true)\n |-- SellCurrency: string (nullable = true)\n |-- SellPrice: double (nullable = true)\n |-- StockOnHand: long (nullable = true)\n |-- StockOnOrder: long (nullable = true)\n |-- SubCategory: string (nullable = true)\n |-- Supplier: string (nullable = true)\n |-- TargetBatchVolume: double (nullable = true)\n |-- Volume: double (nullable = true)\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 7, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "df.select(\"Category\").show()", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+---------------+\n|       Category|\n+---------------+\n|     Technology|\n|Office Supplies|\n|Office Supplies|\n|Office Supplies|\n|Office Supplies|\n|     Technology|\n|     Technology|\n|Office Supplies|\n|Office Supplies|\n|     Technology|\n|Office Supplies|\n|      Furniture|\n|      Furniture|\n|     Technology|\n|Office Supplies|\n|      Furniture|\n|      Furniture|\n|Office Supplies|\n|Office Supplies|\n|Office Supplies|\n+---------------+\nonly showing top 20 rows\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 10, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "df.select('Brand', 'Volume').show()", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+--------+------+\n|   Brand|Volume|\n+--------+------+\n| StarTAC|   0.8|\n|   Xerox|  0.47|\n|   Xerox|  0.55|\n|   Elite|  0.85|\n|  Wilson|  0.12|\n|MicroTAC|  0.55|\n|   V3682|  0.41|\n|   Xerox|  0.84|\n| Staples|  0.12|\n| StarTAC|  0.97|\n|   Avery|  0.13|\n|Anderson|  0.84|\n|   SAFCO|  0.55|\n|   Canon|   0.9|\n|It's Hot|  0.12|\n|Electrix|  0.11|\n|   Safco|  0.07|\n| Catalog|  0.11|\n|  Belkin|  0.99|\n|    Iris|  0.11|\n+--------+------+\nonly showing top 20 rows\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 11, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "df.select(df['Brand'], df['Volume']).show()", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+--------+------+\n|   Brand|Volume|\n+--------+------+\n| StarTAC|   0.8|\n|   Xerox|  0.47|\n|   Xerox|  0.55|\n|   Elite|  0.85|\n|  Wilson|  0.12|\n|MicroTAC|  0.55|\n|   V3682|  0.41|\n|   Xerox|  0.84|\n| Staples|  0.12|\n| StarTAC|  0.97|\n|   Avery|  0.13|\n|Anderson|  0.84|\n|   SAFCO|  0.55|\n|   Canon|   0.9|\n|It's Hot|  0.12|\n|Electrix|  0.11|\n|   Safco|  0.07|\n| Catalog|  0.11|\n|  Belkin|  0.99|\n|    Iris|  0.11|\n+--------+------+\nonly showing top 20 rows\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 9, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "df.select(df['Brand'], df['Volume'] + 1).show()", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+--------+------------------+\n|   Brand|      (Volume + 1)|\n+--------+------------------+\n| StarTAC|               1.8|\n|   Xerox|              1.47|\n|   Xerox|              1.55|\n|   Elite|              1.85|\n|  Wilson|              1.12|\n|MicroTAC|              1.55|\n|   V3682|              1.41|\n|   Xerox|1.8399999999999999|\n| Staples|              1.12|\n| StarTAC|              1.97|\n|   Avery|              1.13|\n|Anderson|1.8399999999999999|\n|   SAFCO|              1.55|\n|   Canon|               1.9|\n|It's Hot|              1.12|\n|Electrix|              1.11|\n|   Safco|              1.07|\n| Catalog|              1.11|\n|  Belkin|              1.99|\n|    Iris|              1.11|\n+--------+------------------+\nonly showing top 20 rows\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 13, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "df.filter(df['Category'] == 'Technology').select(\"Id\",\"Category\").show()", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+--------+----------+\n|      Id|  Category|\n+--------+----------+\n|16342939|Technology|\n|16376266|Technology|\n|16379125|Technology|\n|16402632|Technology|\n|16413246|Technology|\n|16468556|Technology|\n|16492459|Technology|\n|16505852|Technology|\n|16513635|Technology|\n|16554562|Technology|\n|16579736|Technology|\n|16616835|Technology|\n|16627009|Technology|\n|16645340|Technology|\n|16688388|Technology|\n|16704002|Technology|\n|16711687|Technology|\n|16726527|Technology|\n|16728666|Technology|\n|16730738|Technology|\n+--------+----------+\nonly showing top 20 rows\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 14, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "df.groupBy(\"Category\").count().show()", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+---------------+-----+\n|       Category|count|\n+---------------+-----+\n|Office Supplies|   68|\n|     Technology|   21|\n|      Furniture|   11|\n+---------------+-----+\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "# Execute direct SQL queries on DataFrames", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 17, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "df.registerTempTable(\"inventory\")\n# Registers this RDD as a temporary table using the given name.\n# The lifetime of this temporary table is tied to the SQLContext \n#\u00a0that was used to create this DataFrame.\n\nsqlContext.sql(\"SELECT Brand, SellPrice FROM inventory ORDER BY SellPrice DESC LIMIT 5\").collect()", 
            "outputs": [
                {
                    "execution_count": 17, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[Row(Brand=u'Chromcraft', SellPrice=550.98),\n Row(Brand=u'Panasonic', SellPrice=517.48),\n Row(Brand=u'Sharp', SellPrice=499.99),\n Row(Brand=u'Fellowes', SellPrice=387.99),\n Row(Brand=u'Hoover', SellPrice=363.25)]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 18, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "topitems = sqlContext.sql(\"SELECT Brand, SellPrice FROM inventory\")\ntopitems.map(lambda row: (row.Brand, row.SellPrice)).reduceByKey(lambda x,y:max(x,y)).collect()", 
            "outputs": [
                {
                    "execution_count": 18, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[(u'Wilson', 6.75),\n (u'Deflect-O', 7.7),\n (u'Hon', 113.98),\n (u'OIC', 3.58),\n (u'Sanford', 2.88),\n (u'Anderson', 15.23),\n (u'Master', 7.59),\n (u'MicroTAC', 65.99),\n (u'Acme', 8.34),\n (u'Verbatim', 22.24),\n (u'Avery', 40.98),\n (u'Catalog', 67.28),\n (u\"O'Sullivan\", 130.98),\n (u'Imation', 33.98),\n (u'DAX', 5.77),\n (u'Electrix', 13.4),\n (u'Rush', 160.98),\n (u'EcoTones', 4.0),\n (u'U.S.', 99.99),\n (u'Ampad', 4.48),\n (u\"It's Hot\", 7.4),\n (u'TDK', 14.48),\n (u'Acco', 29.74),\n (u'Elite', 8.45),\n (u'Canon', 199.99),\n (u'V3682', 125.99),\n (u'Presstex', 4.55),\n (u'GBC', 122.99),\n (u'Iris', 20.89),\n (u'Multimedia', 162.93),\n (u'Keytronic', 73.98),\n (u'Xerox', 55.98),\n (u'StarTAC', 125.99),\n (u'Fellowes', 387.99),\n (u'Hoover', 363.25),\n (u'Jet-Pak', 35.89),\n (u'Hewlett-Packard', 115.99),\n (u'Newell', 3.28),\n (u'Prang', 2.94),\n (u'Logitech', 100.98),\n (u'AT&T', 15.99),\n (u'XtraLife', 7.84),\n (u'Staples', 35.44),\n (u'Safco', 70.98),\n (u'Speediset', 10.31),\n (u'Sharp', 499.99),\n (u'Soundgear', 204.1),\n (u'Chromcraft', 550.98),\n (u'Microsoft', 20.97),\n (u'Strathmore', 6.78),\n (u'Boston', 43.98),\n (u'Belkin', 80.98),\n (u'Tennsco', 48.91),\n (u'Eldon', 3.34),\n (u'Gyration', 100.97),\n (u'SAFCO', 349.45),\n (u'Panasonic', 517.48)]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 21, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "sqlContext.cacheTable(\"inventory\")", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "# Create DataFrames from \"Row\" RDDs. \n\n<strong>pyspark.sql.Row class is a wrapper to create named columns, i.e., data attributes.</strong>", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 36, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "from pyspark.sql import Row\nrowRdd = sc.parallelize([Row(name=\"Jack\", favouritecoffee=\"Industrial Blend\"), Row(name=\"Jane\", favouritecoffee=\"Decaffeinated\")])\ndf = sqlContext.createDataFrame(rowRdd)\ndf.printSchema()", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "root\n |-- favouritecoffee: string (nullable = true)\n |-- name: string (nullable = true)\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 37, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "df.show()", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+----------------+----+\n| favouritecoffee|name|\n+----------------+----+\n|Industrial Blend|Jack|\n|   Decaffeinated|Jane|\n+----------------+----+\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "# Create a DataFrame from raw text data.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 28, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "netflowdata = sc.textFile(\"swift://CS340.\" + name + \"/NetflowData.txt\")\nnetflowdata.first()", 
            "outputs": [
                {
                    "execution_count": 28, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "u'10.1.0.2,16.2.3.7,12,20K,http'"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 32, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "plainRdd = netflowdata.map(lambda l: l.split(\",\"))\nrddOfRowObjects = plainRdd.map(lambda p: Row(source=p[0], destination=p[1],duration=int(p[2]),bytes_sent=int(p[3][:-1]),protocol=p[4]))\ndfNetflow = sqlContext.createDataFrame(rddOfRowObjects)", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+--------+---------------+\n|protocol|sum(bytes_sent)|\n+--------+---------------+\n|     ftp|           1203|\n|    http|           1810|\n+--------+---------------+\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 34, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "dfNetflow.show()", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+----------+-----------+--------+--------+----------+\n|bytes_sent|destination|duration|protocol|    source|\n+----------+-----------+--------+--------+----------+\n|        20|   16.2.3.7|      12|    http|  10.1.0.2|\n|        24|   12.4.0.3|      16|    http|  18.6.7.1|\n|        20|   11.6.8.2|      15|    http|  13.9.4.3|\n|        40|   17.1.2.1|      19|    http|  15.2.2.9|\n|        58|   14.8.7.4|      26|    http|  12.4.3.8|\n|       100|   13.0.0.1|      27|     ftp|  10.5.1.3|\n|       300|   10.3.4.5|      32|     ftp|  11.1.0.6|\n|        80|   16.5.5.8|      18|     ftp|  19.7.1.2|\n|        20|  16.12.3.7|      12|    http|10.110.0.2|\n|       124|  12.4.0.13|      16|    http| 182.6.7.1|\n|        20|   11.6.8.2|      15|    http| 163.9.4.3|\n|       140|  17.17.2.1|      19|    http| 15.2.12.9|\n|        58| 14.8.71.42|      26|    http|  12.4.3.8|\n|       200|   13.0.0.1|      27|    http| 10.45.1.3|\n|       300|   10.3.4.5|      32|     ftp| 11.1.20.6|\n|       180|   16.5.5.8|      18|    http| 19.47.1.2|\n|        20|   16.2.3.7|      12|    http|  10.1.0.2|\n|        24|   12.4.0.3|      16|    http| 18.6.71.1|\n|        20|   21.6.8.2|      15|    http|  13.9.4.3|\n|        40|   17.1.2.1|      19|    http| 15.22.2.9|\n+----------+-----------+--------+--------+----------+\nonly showing top 20 rows\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 33, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "dfNetflow.select(\"protocol\",\"bytes_sent\").groupBy(\"protocol\").sum().show()", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+--------+---------------+\n|protocol|sum(bytes_sent)|\n+--------+---------------+\n|     ftp|           1203|\n|    http|           1810|\n+--------+---------------+\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "# Work with nested data using SQL.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 38, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "# I am just doing these as prep-work to have a saved json data. \nimport json\nproducts = [{'Product': 'Apple iMac', 'Features': {'Pros': ['Display Resolution', 'Aesthetics'],'Cons': ['Price Expensive', 'Cooling Problem']}},\n              {'Product': 'Dell', 'Features': {'Pros': ['Affordable', 'Fast Customer Service'],'Cons': ['Standard Look & Feel', 'Heavy']}}]\nrdd = sc.parallelize(products)\nrdd.map(lambda x: json.dumps(x)).saveAsTextFile(\"ProductsDump.json\")\n\n# Now continue as usual.\nsrdd = sqlContext.read.json(\"ProductsDump.json\")\nsrdd.printSchema()", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "root\n |-- Features: struct (nullable = true)\n |    |-- Cons: array (nullable = true)\n |    |    |-- element: string (containsNull = true)\n |    |-- Pros: array (nullable = true)\n |    |    |-- element: string (containsNull = true)\n |-- Product: string (nullable = true)\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 41, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "# We need to register a dataframe as a temporary table before querying it with SQL.\nsrdd.registerTempTable(\"Products\")\n#\u00a0Registers the given DataFrame as a temporary table in the SQLContext catalog.\n#\u00a0Temporary tables exist only during the lifetime of this instance of SQLContext.\n\nsqlContext.sql(\"SELECT Features.Pros FROM Products\").collect()", 
            "outputs": [
                {
                    "execution_count": 41, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[Row(Pros=[u'Display Resolution', u'Aesthetics']),\n Row(Pros=[u'Affordable', u'Fast Customer Service'])]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "# Work with nested data using DataFrame API.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 43, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "products = [{'Product': 'Apple iMac', 'Features': {'Pros': ['Display Resolution', 'Aesthetics'],'Cons': ['Price Expensive', 'Cooling Problem']}},\n              {'Product': 'Dell', 'Features': {'Pros': ['Affordable', 'Fast Customer Service'],'Cons': ['Standard Look & Feel', 'Heavy']}}]", 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 44, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "df = sqlContext.createDataFrame(products)", 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "/usr/local/src/spark160master/spark/python/pyspark/sql/context.py:237: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 45, 
            "metadata": {
                "collapsed": false
            }, 
            "source": "df.select(\"Features.Pros\").show()", 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "+--------------------+\n|                Pros|\n+--------------------+\n|[Display Resoluti...|\n|[Affordable, Fast...|\n+--------------------+\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "", 
            "outputs": [], 
            "cell_type": "code"
        }
    ]
}